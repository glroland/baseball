{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Pitch Type Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with the most simplicistic prediction, the goal with this experiment is to predict whether a pitcher will pitch a ball or a strike, given a basic game scenario.\n",
    "\n",
    "Ideas for getting better accuracy:\n",
    "- Filter data based on pitcher (and catcher?).  Do not think this will work because of model training aspect - not transactional.\n",
    "- Is the game packed or is it empty?\n",
    "- Is it at night?\n",
    "- Is it cold?\n",
    "- Is it raining?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from train_tools import SCALER_SUFFIX\n",
    "\n",
    "from train_tools import acquire_data, drop_column, get_config_value\n",
    "from train_tools import scale_int_values, extract_categorical_columns\n",
    "from train_tools import replace_populated_values_with_tf_num, replace_boolean_values_with_tf_num\n",
    "from train_tools import model_train, save_model, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_DB_CONNECTION_STRING = \"postgresql://baseball_app:baseball123@localhost/baseball_db\"\n",
    "ENV_DB_CONNECTION_STRING = \"DB_CONNECTION_STRING\"\n",
    "\n",
    "DEFAULT_OUTPUT_DIR = \"../../../target/models/predict_pitch/\"\n",
    "ENV_OUTPUT_DIR = \"OUTPUT_DIR\"\n",
    "\n",
    "ONNX_FILENAME = \"model.onnx\"\n",
    "ROC_IMAGE_NAME = \"roc.jpg\"\n",
    "\n",
    "ENV_DATASET_SIZE = \"DATASET_SIZE\"\n",
    "DEFAULT_DATASET_SIZE = 25000\n",
    "\n",
    "HAND_LEFT = 0\n",
    "HAND_RIGHT = 1\n",
    "\n",
    "NEURAL_NETWORK_WIDTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Directory: /Users/lroland/Projects/github.com/baseball/target/models/predict_pitch\n"
     ]
    }
   ],
   "source": [
    "output_dir_configured = get_config_value(ENV_OUTPUT_DIR, DEFAULT_OUTPUT_DIR)\n",
    "output_dir = os.path.abspath(output_dir_configured)\n",
    "print (\"Output Directory: \" + output_dir)\n",
    "\n",
    "# ensure the model directory exists\n",
    "if not os.path.exists(output_dir):\n",
    "    print (\"Creating output directory: \" + output_dir)\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire Data\n",
    "\n",
    "Pull relevant attributes from the baseball database as a DataFrame for analysis and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Set Size: 25000\n"
     ]
    }
   ],
   "source": [
    "dataset_size = get_config_value(ENV_DATASET_SIZE, DEFAULT_DATASET_SIZE)\n",
    "if dataset_size is not None and isinstance(dataset_size, str) and len(dataset_size) > 0:\n",
    "    dataset_size = int(dataset_size)\n",
    "print (\"Data Set Size: \" + str(dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "connection failed: connection to server at \"::1\", port 5432 failed: FATAL:  database \"baseball_db\" does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m\n\u001b[1;32m      1\u001b[0m sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124m        select random() as r_id, game_play_atbat.player_code as player_code, pitch_index, pitch_type.pitch_type_cd as pitch_type_cd, home_team_flag, game_play_atbat.score_home as score_home, game_play_atbat.score_visitor as score_visitor, sky, night_flag, temperature, wind_direction, wind_speed, precipitation, field_condition, roster_batter.batting_hand as batting_hand, roster_pitcher.throw_hand as pitching_hand, runner_1b, runner_2b, runner_3b, ball_or_strike,\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m        (select count(*)\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124m        order by r_id    \u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124m      \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     27\u001b[0m db_conn_str \u001b[38;5;241m=\u001b[39m get_config_value(ENV_DB_CONNECTION_STRING, DEFAULT_DB_CONNECTION_STRING)\n\u001b[0;32m---> 28\u001b[0m full_df \u001b[38;5;241m=\u001b[39m \u001b[43macquire_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb_conn_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m full_df\u001b[38;5;241m.\u001b[39minfo()\n",
      "File \u001b[0;32m~/Projects/github.com/baseball/data/src/train/train_tools.py:77\u001b[0m, in \u001b[0;36macquire_data\u001b[0;34m(connection_str, sql, limit)\u001b[0m\n\u001b[1;32m     74\u001b[0m     sql \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(limit)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# pylint: disable=not-context-manager\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpsycopg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection_str\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m sql_connection:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m sql_connection\u001b[38;5;241m.\u001b[39mcursor() \u001b[38;5;28;01mas\u001b[39;00m sql_cursor:\n\u001b[1;32m     79\u001b[0m         sql_cursor\u001b[38;5;241m.\u001b[39mexecute(sql) \u001b[38;5;66;03m#, [])\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/baseball/lib/python3.11/site-packages/psycopg/connection.py:119\u001b[0m, in \u001b[0;36mConnection.connect\u001b[0;34m(cls, conninfo, autocommit, prepare_threshold, context, row_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rv:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m last_ex\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m last_ex\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    121\u001b[0m rv\u001b[38;5;241m.\u001b[39m_autocommit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(autocommit)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row_factory:\n",
      "\u001b[0;31mOperationalError\u001b[0m: connection failed: connection to server at \"::1\", port 5432 failed: FATAL:  database \"baseball_db\" does not exist"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "        select random() as r_id, game_play_atbat.player_code as player_code, pitch_index, pitch_type.pitch_type_cd as pitch_type_cd, home_team_flag, game_play_atbat.score_home as score_home, game_play_atbat.score_visitor as score_visitor, sky, night_flag, temperature, wind_direction, wind_speed, precipitation, field_condition, roster_batter.batting_hand as batting_hand, roster_pitcher.throw_hand as pitching_hand, runner_1b, runner_2b, runner_3b, ball_or_strike,\n",
    "        (select count(*)\n",
    "         from game_play_atbat pc_atbat, game_play_atbat_pitch pc_pitch, pitch_type pc_pitch_type\n",
    "         where pc_pitch.game_id = pc_atbat.game_id\n",
    "         and pc_pitch.play_index = pc_atbat.play_index\n",
    "         and pc_atbat.game_id = game.game_id\n",
    "         and pc_atbat.pitcher = game_play_atbat.pitcher  \n",
    "         and pc_pitch_type.pitch_type_cd = pc_pitch.pitch_type_cd\n",
    "         and pc_pitch_type.ball_or_strike is not null\n",
    "         and pc_pitch.play_index <= game_play_atbat.play_index\n",
    "         and pc_pitch.pitch_index < game_play_atbat_pitch.pitch_index\n",
    "        ) as pitch_count\n",
    "        from game, game_play_atbat, game_play_atbat_pitch, roster as roster_batter, roster as roster_pitcher, pitch_type\n",
    "        where game.game_id = game_play_atbat.game_id\n",
    "        and game_play_atbat.game_id = game_play_atbat_pitch.game_id\n",
    "        and game_play_atbat.play_index = game_play_atbat_pitch.play_index\n",
    "        and roster_batter.player_code = game_play_atbat.player_code\n",
    "        and roster_batter.season_year = date_part('year', game.game_date)\n",
    "        and roster_pitcher.player_code = game_play_atbat.pitcher\n",
    "        and roster_pitcher.season_year = roster_batter.season_year\n",
    "        and pitch_type.pitch_type_cd = game_play_atbat_pitch.pitch_type_cd\n",
    "        and pitch_type.ball_or_strike is not null\n",
    "        order by r_id    \n",
    "      \"\"\"\n",
    "\n",
    "db_conn_str = get_config_value(ENV_DB_CONNECTION_STRING, DEFAULT_DB_CONNECTION_STRING)\n",
    "full_df = acquire_data(db_conn_str, sql, dataset_size)\n",
    "\n",
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score_deficit(row):\n",
    "    is_home = row[\"home_team_flag\"]\n",
    "    score_home = row[\"score_home\"]\n",
    "    score_visitor = row[\"score_visitor\"]\n",
    "\n",
    "    if is_home:\n",
    "        return score_home - score_visitor\n",
    "    else:\n",
    "        return score_visitor - score_home\n",
    "\n",
    "full_df['score_deficit'] = full_df.apply(lambda x: calculate_score_deficit(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Model Training\n",
    "\n",
    "Prepare data for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus data frame on prediction values\n",
    "df = full_df[[\"pitch_index\", \"runner_1b\", \"runner_2b\", \"runner_3b\", \"home_team_flag\", \"score_deficit\", \n",
    "              \"night_flag\", \"pitch_count\", \"ball_or_strike\"]]\n",
    "df = df[df['ball_or_strike'].notnull()]\n",
    "\n",
    "df = df.convert_dtypes()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_populated_values_with_tf_num(df, 'runner_1b', 'runner_1b_value', True)\n",
    "replace_populated_values_with_tf_num(df, 'runner_2b', 'runner_2b_value', True)\n",
    "replace_populated_values_with_tf_num(df, 'runner_3b', 'runner_3b_value', True)\n",
    "\n",
    "replace_boolean_values_with_tf_num(df, \"home_team_flag\", 'is_home', True)\n",
    "replace_boolean_values_with_tf_num(df, \"night_flag\", 'is_night', True)\n",
    "\n",
    "scale_int_values(df, 'score_deficit', 'score_deficit_scaled', True, \n",
    "                 output_dir + \"/\" + \"score_deficit\" + SCALER_SUFFIX)\n",
    "scale_int_values(df, 'pitch_count', 'pitch_count', False,\n",
    "                 output_dir + \"/\" + \"pitch_count\" + SCALER_SUFFIX)\n",
    "scale_int_values(df, 'pitch_index', 'pitch_index', False,\n",
    "                 output_dir + \"/\" + \"pitch_index\" + SCALER_SUFFIX)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_categorical_columns(df, [\"ball_or_strike\"])\n",
    "drop_column(df, \"ball_or_strike_B\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pitch_index\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ball_or_strike_S\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pitch_index\"].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "Train a classification model using the prepared data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = df.shape[1] - 1\n",
    "print(f\"Number of Features: {num_features}\")\n",
    "\n",
    "print(\"Columns and their respective order for inferences:\")\n",
    "df.columns[0:num_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data\n",
    "X = df.iloc[:, 0:num_features]\n",
    "y = df.iloc[:, num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to 2D PyTorch tensors\n",
    "Xt = torch.tensor(X.values, dtype=torch.float32)\n",
    "yt = torch.tensor(y.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PitchPredictionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(num_features, num_features*NEURAL_NETWORK_WIDTH)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(num_features*NEURAL_NETWORK_WIDTH, num_features*NEURAL_NETWORK_WIDTH)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(num_features*NEURAL_NETWORK_WIDTH, num_features*NEURAL_NETWORK_WIDTH)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(num_features*NEURAL_NETWORK_WIDTH, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xt, yt, train_size=0.7, shuffle=True)\n",
    "print (\"Training Shapes: X_train=\" + str(X_train.shape) + \" y_train=\" + str(y_train.shape) + \" X_test=\" + str(X_test.shape) + \" y_test=\" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PitchPredictionModel()\n",
    "final_acc = model_train(model, X_train, y_train, X_test, y_test)\n",
    "print(f\"Final model accuracy: {final_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = output_dir + \"/\" + ROC_IMAGE_NAME\n",
    "print(\"ROC Image Output Filename: \" + output_filename)\n",
    "\n",
    "evaluate_model(model, X_test, y_test, output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model\n",
    "\n",
    "Save the model to disk for use by an inference service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = output_dir + \"/\" + ONNX_FILENAME\n",
    "print (\"ONNX Model Output Filename: \" + output_filename)\n",
    "save_model(model, num_features, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseball",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
