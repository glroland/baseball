{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Predict Next Play Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from train_tools import SCALER_SUFFIX\n",
    "\n",
    "from train_tools import acquire_data, get_config_value\n",
    "from train_tools import scale_int_values, extract_categorical_columns\n",
    "from train_tools import replace_populated_values_with_tf_num\n",
    "from train_tools import model_train, save_model, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_DB_CONNECTION_STRING = \"postgresql://baseball_app:baseball123@localhost/baseball_db\"\n",
    "ENV_DB_CONNECTION_STRING = \"DB_CONNECTION_STRING\"\n",
    "\n",
    "DEFAULT_OUTPUT_DIR = \"../../../target/models/predict_play/\"\n",
    "ENV_OUTPUT_DIR = \"OUTPUT_DIR\"\n",
    "\n",
    "ONNX_FILENAME = \"model.onnx\"\n",
    "ROC_IMAGE_NAME = \"roc.jpg\"\n",
    "\n",
    "ENV_DATASET_SIZE = \"DATASET_SIZE\"\n",
    "DEFAULT_DATASET_SIZE = 25000\n",
    "\n",
    "HAND_LEFT = 0\n",
    "HAND_RIGHT = 1\n",
    "\n",
    "NEURAL_NETWORK_WIDTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_configured = get_config_value(ENV_OUTPUT_DIR, DEFAULT_OUTPUT_DIR)\n",
    "output_dir = os.path.abspath(output_dir_configured)\n",
    "print (\"Output Directory: \" + output_dir)\n",
    "\n",
    "# ensure the model directory exists\n",
    "if not os.path.exists(output_dir):\n",
    "    print (\"Creating output directory: \" + output_dir)\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire Data\n",
    "\n",
    "Pull relevant attributes from the baseball database as a DataFrame for analysis and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = get_config_value(ENV_DATASET_SIZE, DEFAULT_DATASET_SIZE)\n",
    "if dataset_size is not None and isinstance(dataset_size, str) and len(dataset_size) > 0:\n",
    "    dataset_size = int(dataset_size)\n",
    "print (\"Data Set Size: \" + str(dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "        select random() as r_id, game_play_atbat.player_code as player_code, pitch_index, home_team_flag, game_play_atbat.score_home as score_home, game_play_atbat.score_visitor as score_visitor, sky, night_flag, temperature, wind_direction, wind_speed, precipitation, field_condition, roster_batter.batting_hand as batting_hand, roster_pitcher.throw_hand as pitching_hand, runner_1b, runner_2b, runner_3b, primary_play_type_cd, outs,\n",
    "        (select count(*)\n",
    "         from game_play_atbat pc_atbat, game_play_atbat_pitch pc_pitch, pitch_type pc_pitch_type\n",
    "         where pc_pitch.game_id = pc_atbat.game_id\n",
    "         and pc_pitch.play_index = pc_atbat.play_index\n",
    "         and pc_atbat.game_id = game.game_id\n",
    "         and pc_atbat.pitcher = game_play_atbat.pitcher  \n",
    "         and pc_pitch_type.pitch_type_cd = pc_pitch.pitch_type_cd\n",
    "         and pc_pitch_type.ball_or_strike is not null\n",
    "         and pc_pitch.play_index <= game_play_atbat.play_index\n",
    "         and pc_pitch.pitch_index < game_play_atbat_pitch.pitch_index\n",
    "        ) as pitch_count\n",
    "        from game, game_play_atbat, game_play_atbat_pitch, roster as roster_batter, roster as roster_pitcher\n",
    "        where game.game_id = game_play_atbat.game_id\n",
    "        and game_play_atbat.game_id = game_play_atbat_pitch.game_id\n",
    "        and game_play_atbat.play_index = game_play_atbat_pitch.play_index\n",
    "        and roster_batter.player_code = game_play_atbat.player_code\n",
    "        and roster_batter.season_year = date_part('year', game.game_date)\n",
    "        and roster_pitcher.player_code = game_play_atbat.pitcher\n",
    "        and roster_pitcher.season_year = roster_batter.season_year\n",
    "        order by r_id        \n",
    "      \"\"\"\n",
    "\n",
    "db_conn_str = get_config_value(ENV_DB_CONNECTION_STRING, DEFAULT_DB_CONNECTION_STRING)\n",
    "full_df = acquire_data(db_conn_str, sql, dataset_size)\n",
    "\n",
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score_deficit(row):\n",
    "    is_home = row[\"home_team_flag\"]\n",
    "    score_home = row[\"score_home\"]\n",
    "    score_visitor = row[\"score_visitor\"]\n",
    "\n",
    "    if is_home:\n",
    "        return score_home - score_visitor\n",
    "    else:\n",
    "        return score_visitor - score_home\n",
    "\n",
    "full_df['score_deficit'] = full_df.apply(lambda x: calculate_score_deficit(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Model Training\n",
    "\n",
    "Prepare data for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus data frame on prediction values\n",
    "# - maybes - wind_direction, home_team_flag, night_flag\n",
    "df = full_df[[\"pitch_index\", \"pitch_count\", \"batting_hand\", \"pitching_hand\", \"runner_1b\", \"runner_2b\", \"runner_3b\", \"outs\", \"score_deficit\", \"primary_play_type_cd\"]]\n",
    "\n",
    "df = df.convert_dtypes()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_int_values(df, 'pitch_index', 'pitch_index_scaled', True,\n",
    "                 output_dir + \"/\" + \"pitch_index\" + SCALER_SUFFIX)\n",
    "scale_int_values(df, 'pitch_count', 'pitch_count_scaled', True,\n",
    "                 output_dir + \"/\" + \"pitch_count\" + SCALER_SUFFIX)\n",
    "scale_int_values(df, 'score_deficit', 'score_deficit_scaled', True,\n",
    "                 output_dir + \"/\" + \"score_deficit\" + SCALER_SUFFIX)\n",
    "\n",
    "replace_populated_values_with_tf_num(df, 'runner_1b', 'runner_1b_value', True)\n",
    "replace_populated_values_with_tf_num(df, 'runner_2b', 'runner_2b_value', True)\n",
    "replace_populated_values_with_tf_num(df, 'runner_3b', 'runner_3b_value', True)\n",
    "\n",
    "df = extract_categorical_columns(df, [\"batting_hand\", \"pitching_hand\", \"outs\", \"primary_play_type_cd\"])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "Train a classification model using the prepared data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pitch_index_scaled\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_x = 15\n",
    "size_y = df.shape[1] - size_x\n",
    "print(f\"Number of Features (X): {size_x}\")\n",
    "print(f\"Length of Outputs (y): {size_y}\")\n",
    "\n",
    "print(\"Columns and their respective order for inferences:\")\n",
    "df.columns[0:size_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.convert_dtypes()\n",
    "print(\"Model Inputs:\")\n",
    "df.info()\n",
    "\n",
    "# Extract data\n",
    "X = df.iloc[:, 0:size_x]\n",
    "y = df.iloc[:, size_x:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to 2D PyTorch tensors\n",
    "Xt = torch.tensor(X.values.astype(float), dtype=torch.float32)\n",
    "yt = torch.tensor(y.values.astype(bool), dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PitchPredictionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(size_x, size_x*NEURAL_NETWORK_WIDTH)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(size_x*NEURAL_NETWORK_WIDTH, size_x*NEURAL_NETWORK_WIDTH)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(size_x*NEURAL_NETWORK_WIDTH, size_x*NEURAL_NETWORK_WIDTH)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(size_x*NEURAL_NETWORK_WIDTH, size_y)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xt, yt, train_size=0.7, shuffle=True)\n",
    "print (\"Training Shapes: X_train=\" + str(X_train.shape) + \" y_train=\" + str(y_train.shape) + \" X_test=\" + str(X_test.shape) + \" y_test=\" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PitchPredictionModel()\n",
    "final_acc = model_train(model, X_train, y_train, X_test, y_test)\n",
    "print(f\"Final model accuracy: {final_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = output_dir + \"/\" + ROC_IMAGE_NAME\n",
    "print(\"ROC Image Output Filename: \" + output_filename)\n",
    "\n",
    "y_column_names = df.columns[size_x:].values\n",
    "y_column_descriptions = [c.replace(\"primary_play_type_cd_\", \"\") for c in y_column_names ]\n",
    "\n",
    "print(\"Model Outputs:\")\n",
    "print (y_column_descriptions)\n",
    "\n",
    "evaluate_model(model, X_test, y_test, output_filename, y_column_descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model\n",
    "\n",
    "Save the model to disk for use by an inference service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = output_dir + \"/\" + ONNX_FILENAME\n",
    "print (\"ONNX Model Output Filename: \" + output_filename)\n",
    "save_model(model, size_x, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseball",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
